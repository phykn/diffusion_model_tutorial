{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forward and Reverse process\n",
    "The diffusion models make data into a gaussian noise (latent vector) and restore it again. The former is called the forward process, and the latter is called the reverse process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward process\n",
    "In the forward process, we add a gaussian noise to the data step by step (usually hundreds of steps). The transform of an individual step is defined as follows.\n",
    "$$\n",
    "\\begin{aligned}\n",
    "x_{t} &= q(x_{t}|x_{t-1}) \\\\\n",
    "&= N(x_{t}, \\sqrt{1-\\beta_{t}}x_{t-1}, \\beta_{t}\\mathrm{I})\n",
    "\\end{aligned}\n",
    "$$\n",
    "where $\\beta_{t}$ is a coefficient in $(0, 1)$.\n",
    "\n",
    "The $x_{t}$ is sampled from a gaussian distribution with mean $\\sqrt{1-\\beta_{t}}x_{t-1}$ and variance $\\beta_{t}$. Because the mean is slightly smaller than $x_{t-1}$ by $\\sqrt{1-\\beta}$, the overall variance remains nearly constant. \n",
    "$$\n",
    "\\begin{aligned}\n",
    "Var(x_{t}) &= Var[N(x_{t}, \\sqrt{1-\\beta_{t}}x_{t-1}, \\beta_{t}\\mathrm{I})] \\\\\n",
    "&= Var(\\sqrt{1-\\beta_{t}}x_{t-1} + \\sqrt{\\beta_{t}} \\epsilon) \\\\\n",
    "&= Var(\\sqrt{1-\\beta_{t}}x_{t-1}) + Var(\\sqrt{\\beta_{t}} \\epsilon) \\\\\n",
    "&= (1-\\beta_{t}) Var(x_{t-1}) + \\beta_{t} \\\\\n",
    "&\\sim 1 - \\beta_{t} + \\beta_{t} \\quad (\\text{let the variance of } x_{t-1} \\text{ is about } 1) \\\\ \n",
    "&= 1\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "The total transform from $x_{0}$ to $x_{T}$ is as follows.\n",
    "$$\n",
    "\\begin{aligned}\n",
    "x_{1:T} &= q(x_{1:T}|x_{0}) \\\\\n",
    "&= \\prod_{t=1}^{T} q(x_{t}|x_{t-1})\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "The reparameterization trick allows $x_{t}$ to be expressed by $x_{0}$ and $\\beta_{t}$.\n",
    "$$\n",
    "\\begin{aligned}\n",
    "x_{t} &= q(x_{t}|x_{t-1}) \\\\\n",
    "&= N(x_{t}, \\sqrt{1-\\beta_{t}}x_{t-1}, \\beta_{t}\\mathrm{I}) \\\\\n",
    "&= \\sqrt{1-\\beta_{t}}x_{t-1} + \\sqrt{\\beta_{t}} \\epsilon_{t-1} \\\\\n",
    "&= \\sqrt{\\alpha_{t}}x_{t-1} + \\sqrt{1-\\alpha_{t}} \\epsilon_{t-1} \\quad (\\alpha_{t}=1-\\beta_{t}) \\\\\n",
    "&= \\sqrt{\\alpha_{t}}(\\sqrt{\\alpha_{t-1}}x_{t-2} + \\sqrt{1-\\alpha_{t-1}} \\epsilon_{t-2}) + \\sqrt{1-\\alpha_{t}} \\epsilon_{t-1} \\\\\n",
    "&= \\sqrt{\\alpha_{t}\\alpha_{t-1}}x_{t-2} + \\sqrt{\\alpha_{t}}\\sqrt{1-\\alpha_{t-1}} \\epsilon_{t-2} + \\sqrt{1-\\alpha_{t}} \\epsilon_{t-1} \\\\\n",
    "&= \\sqrt{\\alpha_{t}\\alpha_{t-1}}x_{t-2} + \\sqrt{\\alpha_{t}-\\alpha_{t}\\alpha_{t-1}+1-\\alpha_{t}} \\bar{\\epsilon} \\quad (\\bar{\\epsilon} \\sim N(0, \\mathbf{I})) \\\\\n",
    "&= \\sqrt{\\alpha_{t}\\alpha_{t-1}}x_{t-2} + \\sqrt{1-\\alpha_{t}\\alpha_{t-1}} \\bar{\\epsilon} \\\\\n",
    "&= \\sqrt{\\alpha_{t}\\alpha_{t-1}\\alpha_{t-2}}x_{t-3} + \\sqrt{1-\\alpha_{t}\\alpha_{t-1}\\alpha_{t-2}} \\bar{\\epsilon} \\\\\n",
    "&= ... \\\\\n",
    "&= \\sqrt{\\alpha_{t}\\alpha_{t-1}...\\alpha_{1}}x_{0} + \\sqrt{1-\\alpha_{t}\\alpha_{t-1}...\\alpha_{1}} \\bar{\\epsilon} \\\\\n",
    "&= \\sqrt{\\bar{\\alpha}} x_{0} + \\sqrt{1-\\bar{\\alpha}} \\epsilon \\quad (\\bar{\\alpha}=\\alpha_{t}\\alpha_{t-1}...\\alpha_{1})\\\\\n",
    "&= N(x_{t}; \\sqrt{\\bar{\\alpha}} x_{0}, (1-\\bar{\\alpha})\\mathbf{I}) \\\\\n",
    "\\therefore q(x_{t}|x_{0}) &= N(x_{t}; \\sqrt{\\bar{\\alpha}} x_{0}, (1-\\bar{\\alpha})\\mathbf{I})\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "65b5f243489bd9358788296533fc03025fea49f65e08ef6aa7a40b96c7113e3c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
