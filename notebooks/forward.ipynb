{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward process\n",
    "In the forward process, we sequentially add gaussian noise to the data, typically over hundreds of steps. The transformation of each individual step is defined as\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "x_{t} &= q(x_{t}|x_{t-1}) \\\\\n",
    "&= \\mathcal{N}(x_{t}; \\sqrt{1-\\beta_{t}}x_{t-1}, \\beta_{t}\\mathrm{I})\n",
    "\\end{aligned}\n",
    "$$\n",
    "where $\\beta_{t}$ is a coefficient in $(0, 1)$.\n",
    "\n",
    "$x_t$ is sampled from a gaussian distribution with a mean of $\\sqrt{1-\\beta_t}x_{t-1}$ and a variance of $\\beta_t$. The mean is slightly smaller than $x_{t-1}$ by a factor of $\\sqrt{1-\\beta_t}$, which helps to maintain the overall variance at a nearly constant level. Please refer to the below equation.\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "Var(x_{t}) &= Var[\\mathcal{N}(x_{t}; \\sqrt{1-\\beta_{t}}x_{t-1}, \\beta_{t}\\mathrm{I})] \\\\\n",
    "&= Var(\\sqrt{1-\\beta_{t}}x_{t-1} + \\sqrt{\\beta_{t}} \\epsilon) \\quad (\\text{reparameterization trick})\\\\\n",
    "&= Var(\\sqrt{1-\\beta_{t}}x_{t-1}) + Var(\\sqrt{\\beta_{t}} \\epsilon) \\\\\n",
    "&= (1-\\beta_{t}) Var(x_{t-1}) + \\beta_{t} \\\\\n",
    "&\\sim 1 - \\beta_{t} + \\beta_{t} \\quad (\\text{assume the variance of } x_{t-1} \\text{ is about } 1) \\\\ \n",
    "&= 1\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "The overall transformation from the initial image $x_0$ to the image at time $T$, $x_T$, can be expressed as follows.\n",
    "\n",
    "$$\n",
    "x_{1:T} = q(x_{1:T}|x_{0}) = \\prod_{t=1}^{T} q(x_{t}|x_{t-1})\n",
    "$$\n",
    "\n",
    "However, the aforementioned equation involves multi-step calculations that can be time-consuming. Therefore, it may be beneficial to use a closed-form expression.\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "x_{t} &= q(x_{t}|x_{t-1}) \\\\\n",
    "&= \\mathcal{N}(x_{t}; \\sqrt{1-\\beta_{t}}x_{t-1}, \\beta_{t}\\mathrm{I}) \\\\\n",
    "&= \\sqrt{1-\\beta_{t}}x_{t-1} + \\sqrt{\\beta_{t}} \\epsilon_{t-1} \\\\\n",
    "&= \\sqrt{\\alpha_{t}}x_{t-1} + \\sqrt{1-\\alpha_{t}} \\epsilon_{t-1} \\quad (\\alpha_{t}=1-\\beta_{t}) \\\\\n",
    "&= \\sqrt{\\alpha_{t}}(\\sqrt{\\alpha_{t-1}}x_{t-2} + \\sqrt{1-\\alpha_{t-1}} \\epsilon_{t-2}) + \\sqrt{1-\\alpha_{t}} \\epsilon_{t-1} \\\\\n",
    "&= \\sqrt{\\alpha_{t}\\alpha_{t-1}}x_{t-2} + \\sqrt{\\alpha_{t}}\\sqrt{1-\\alpha_{t-1}} \\epsilon_{t-2} + \\sqrt{1-\\alpha_{t}} \\epsilon_{t-1} \\\\\n",
    "&= \\sqrt{\\alpha_{t}\\alpha_{t-1}}x_{t-2} + \\sqrt{\\alpha_{t}-\\alpha_{t}\\alpha_{t-1}+1-\\alpha_{t}} \\bar{\\epsilon} \\quad (\\bar{\\epsilon} \\sim \\mathcal{N}(0, \\mathbf{I})) \\\\\n",
    "&= \\sqrt{\\alpha_{t}\\alpha_{t-1}}x_{t-2} + \\sqrt{1-\\alpha_{t}\\alpha_{t-1}} \\bar{\\epsilon} \\\\\n",
    "&= \\sqrt{\\alpha_{t}\\alpha_{t-1}\\alpha_{t-2}}x_{t-3} + \\sqrt{1-\\alpha_{t}\\alpha_{t-1}\\alpha_{t-2}} \\bar{\\epsilon} \\\\\n",
    "&= ... \\\\\n",
    "&= \\sqrt{\\alpha_{t}\\alpha_{t-1}...\\alpha_{1}}x_{0} + \\sqrt{1-\\alpha_{t}\\alpha_{t-1}...\\alpha_{1}} \\bar{\\epsilon} \\\\\n",
    "&= \\sqrt{\\bar{\\alpha}_{t}} x_{0} + \\sqrt{1-\\bar{\\alpha}_{t}} \\epsilon \\quad (\\bar{\\alpha}_{t}=\\alpha_{t}\\alpha_{t-1}...\\alpha_{1})\\\\\n",
    "\\\\\n",
    "\\therefore q(x_{t}|x_{0}) &= \\sqrt{\\bar{\\alpha}_{t}} x_{0} + \\sqrt{1-\\bar{\\alpha}_{t}} \\epsilon\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "where $\\bar{\\alpha}_{t}=\\alpha_{t} \\times \\alpha_{t-1} \\times ... \\times \\alpha_{1}$."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.10 (tags/v3.8.10:3d8993a, May  3 2021, 11:48:03) [MSC v.1928 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "65b5f243489bd9358788296533fc03025fea49f65e08ef6aa7a40b96c7113e3c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
